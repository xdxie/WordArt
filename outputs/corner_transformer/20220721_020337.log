2022-07-21 02:03:37,158 - mmocr - INFO - Environment info:
------------------------------------------------------------
sys.platform: linux
Python: 3.7.13 (default, Mar 29 2022, 02:18:16) [GCC 7.5.0]
CUDA available: True
GPU 0,1: NVIDIA GeForce RTX 3090
CUDA_HOME: None
GCC: gcc (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
PyTorch: 1.10.2
PyTorch compiling details: PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX512
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.2
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.2, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

TorchVision: 0.11.3
OpenCV: 4.6.0
MMCV: 1.6.0
MMCV Compiler: GCC 9.3
MMCV CUDA Compiler: 11.3
MMOCR: 0.6.0+1755dad
------------------------------------------------------------

2022-07-21 02:03:38,222 - mmocr - INFO - Distributed training: True
2022-07-21 02:03:39,183 - mmocr - INFO - Config:
log_config = dict(interval=5, hooks=[dict(type='TextLoggerHook')])
dist_params = dict(backend='nccl')
log_level = 'INFO'
load_from = None
resume_from = None
workflow = [('train', 1)]
opencv_num_threads = 0
mp_start_method = 'fork'
img_norm_cfg = dict(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
train_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(
        type='ResizeOCR',
        height=32,
        min_width=128,
        max_width=128,
        keep_aspect_ratio=False,
        width_downsample_ratio=0.25),
    dict(
        type='RandomWrapper',
        p=0.5,
        transforms=[
            dict(
                type='OneOfWrapper',
                transforms=[
                    dict(type='RandomRotateTextDet', max_angle=15),
                    dict(
                        type='TorchVisionWrapper',
                        op='RandomAffine',
                        degrees=15,
                        translate=(0.3, 0.3),
                        scale=(0.5, 2.0),
                        shear=(-45, 45)),
                    dict(
                        type='TorchVisionWrapper',
                        op='RandomPerspective',
                        distortion_scale=0.5,
                        p=1)
                ])
        ]),
    dict(
        type='RandomWrapper',
        p=0.25,
        transforms=[
            dict(type='PyramidRescale'),
            dict(
                type='Albu',
                transforms=[
                    dict(type='GaussNoise', var_limit=(20, 20), p=0.5),
                    dict(type='MotionBlur', blur_limit=6, p=0.5)
                ])
        ]),
    dict(
        type='RandomWrapper',
        p=0.25,
        transforms=[
            dict(
                type='TorchVisionWrapper',
                op='ColorJitter',
                brightness=0.5,
                saturation=0.5,
                contrast=0.5,
                hue=0.1)
        ]),
    dict(type='ToTensorOCR'),
    dict(
        type='NormalizeOCR',
        mean=[0.485, 0.456, 0.406],
        std=[0.229, 0.224, 0.225]),
    dict(
        type='Collect',
        keys=['img'],
        meta_keys=[
            'filename', 'ori_shape', 'img_shape', 'text', 'valid_ratio',
            'resize_shape', 'img_norm_cfg'
        ])
]
test_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(
        type='MultiRotateAugOCR',
        rotate_degrees=[0, 90, 270],
        transforms=[
            dict(
                type='ResizeOCR',
                height=32,
                min_width=128,
                max_width=128,
                keep_aspect_ratio=False,
                width_downsample_ratio=0.25),
            dict(type='ToTensorOCR'),
            dict(
                type='NormalizeOCR',
                mean=[0.485, 0.456, 0.406],
                std=[0.229, 0.224, 0.225]),
            dict(
                type='Collect',
                keys=['img'],
                meta_keys=[
                    'filename', 'ori_shape', 'img_shape', 'valid_ratio',
                    'resize_shape', 'img_norm_cfg', 'ori_filename'
                ])
        ])
]
train_root = 'data/mixture'
train_img_prefix1 = 'data/mixture/Syn90k/mnt/ramdisk/max/90kDICT32px'
train_ann_file1 = 'data/mixture/Syn90k/label.lmdb'
train1 = dict(
    type='OCRDataset',
    img_prefix='data/mixture/Syn90k/mnt/ramdisk/max/90kDICT32px',
    ann_file='data/mixture/Syn90k/label.lmdb',
    loader=dict(
        type='AnnFileLoader',
        repeat=1,
        file_format='lmdb',
        parser=dict(type='LineJsonParser', keys=['filename', 'text'])),
    pipeline=None,
    test_mode=False)
train_img_prefix2 = 'data/mixture/SynthText/synthtext/SynthText_patch_horizontal'
train_ann_file2 = 'data/mixture/SynthText/label.lmdb'
train2 = dict(
    type='OCRDataset',
    img_prefix='data/mixture/SynthText/synthtext/SynthText_patch_horizontal',
    ann_file='data/mixture/SynthText/label.lmdb',
    loader=dict(
        type='AnnFileLoader',
        repeat=1,
        file_format='lmdb',
        parser=dict(type='LineJsonParser', keys=['filename', 'text'])),
    pipeline=None,
    test_mode=False)
train_list = [
    dict(
        type='OCRDataset',
        img_prefix='data/mixture/Syn90k/mnt/ramdisk/max/90kDICT32px',
        ann_file='data/mixture/Syn90k/label.lmdb',
        loader=dict(
            type='AnnFileLoader',
            repeat=1,
            file_format='lmdb',
            parser=dict(type='LineJsonParser', keys=['filename', 'text'])),
        pipeline=None,
        test_mode=False),
    dict(
        type='OCRDataset',
        img_prefix=
        'data/mixture/SynthText/synthtext/SynthText_patch_horizontal',
        ann_file='data/mixture/SynthText/label.lmdb',
        loader=dict(
            type='AnnFileLoader',
            repeat=1,
            file_format='lmdb',
            parser=dict(type='LineJsonParser', keys=['filename', 'text'])),
        pipeline=None,
        test_mode=False)
]
test_root = 'data/mixture'
test_img_prefix1 = 'data/mixture/IIIT5K/'
test_img_prefix2 = 'data/mixture/svt/'
test_img_prefix3 = 'data/mixture/icdar_2013/'
test_img_prefix4 = 'data/mixture/icdar_2015/'
test_img_prefix5 = 'data/mixture/svtp/'
test_img_prefix6 = 'data/mixture/ct80/'
test_img_prefix7 = 'data/mixture/WordArt/'
test_ann_file1 = 'data/mixture/IIIT5K/test_label.txt'
test_ann_file2 = 'data/mixture/svt/test_label.txt'
test_ann_file3 = 'data/mixture/icdar_2013/test_label_1015.txt'
test_ann_file4 = 'data/mixture/icdar_2015/test_label.txt'
test_ann_file5 = 'data/mixture/svtp/test_label.txt'
test_ann_file6 = 'data/mixture/ct80/test_label.txt'
test_ann_file7 = 'data/mixture/WordArt/test_label.txt'
test1 = dict(
    type='OCRDataset',
    img_prefix='data/mixture/IIIT5K/',
    ann_file='data/mixture/IIIT5K/test_label.txt',
    loader=dict(
        type='AnnFileLoader',
        repeat=1,
        file_format='txt',
        parser=dict(
            type='LineStrParser',
            keys=['filename', 'text'],
            keys_idx=[0, 1],
            separator=' ')),
    pipeline=None,
    test_mode=True)
test2 = dict(
    type='OCRDataset',
    img_prefix='data/mixture/svt/',
    ann_file='data/mixture/svt/test_label.txt',
    loader=dict(
        type='AnnFileLoader',
        repeat=1,
        file_format='txt',
        parser=dict(
            type='LineStrParser',
            keys=['filename', 'text'],
            keys_idx=[0, 1],
            separator=' ')),
    pipeline=None,
    test_mode=True)
test3 = dict(
    type='OCRDataset',
    img_prefix='data/mixture/icdar_2013/',
    ann_file='data/mixture/icdar_2013/test_label_1015.txt',
    loader=dict(
        type='AnnFileLoader',
        repeat=1,
        file_format='txt',
        parser=dict(
            type='LineStrParser',
            keys=['filename', 'text'],
            keys_idx=[0, 1],
            separator=' ')),
    pipeline=None,
    test_mode=True)
test4 = dict(
    type='OCRDataset',
    img_prefix='data/mixture/icdar_2015/',
    ann_file='data/mixture/icdar_2015/test_label.txt',
    loader=dict(
        type='AnnFileLoader',
        repeat=1,
        file_format='txt',
        parser=dict(
            type='LineStrParser',
            keys=['filename', 'text'],
            keys_idx=[0, 1],
            separator=' ')),
    pipeline=None,
    test_mode=True)
test5 = dict(
    type='OCRDataset',
    img_prefix='data/mixture/svtp/',
    ann_file='data/mixture/svtp/test_label.txt',
    loader=dict(
        type='AnnFileLoader',
        repeat=1,
        file_format='txt',
        parser=dict(
            type='LineStrParser',
            keys=['filename', 'text'],
            keys_idx=[0, 1],
            separator=' ')),
    pipeline=None,
    test_mode=True)
test6 = dict(
    type='OCRDataset',
    img_prefix='data/mixture/ct80/',
    ann_file='data/mixture/ct80/test_label.txt',
    loader=dict(
        type='AnnFileLoader',
        repeat=1,
        file_format='txt',
        parser=dict(
            type='LineStrParser',
            keys=['filename', 'text'],
            keys_idx=[0, 1],
            separator=' ')),
    pipeline=None,
    test_mode=True)
test7 = dict(
    type='OCRDataset',
    img_prefix='data/mixture/WordArt/',
    ann_file='data/mixture/WordArt/test_label.txt',
    loader=dict(
        type='AnnFileLoader',
        repeat=1,
        file_format='txt',
        parser=dict(
            type='LineStrParser',
            keys=['filename', 'text'],
            keys_idx=[0, 1],
            separator=' ')),
    pipeline=None,
    test_mode=True)
test_list = [
    dict(
        type='OCRDataset',
        img_prefix='data/mixture/IIIT5K/',
        ann_file='data/mixture/IIIT5K/test_label.txt',
        loader=dict(
            type='AnnFileLoader',
            repeat=1,
            file_format='txt',
            parser=dict(
                type='LineStrParser',
                keys=['filename', 'text'],
                keys_idx=[0, 1],
                separator=' ')),
        pipeline=None,
        test_mode=True),
    dict(
        type='OCRDataset',
        img_prefix='data/mixture/svt/',
        ann_file='data/mixture/svt/test_label.txt',
        loader=dict(
            type='AnnFileLoader',
            repeat=1,
            file_format='txt',
            parser=dict(
                type='LineStrParser',
                keys=['filename', 'text'],
                keys_idx=[0, 1],
                separator=' ')),
        pipeline=None,
        test_mode=True),
    dict(
        type='OCRDataset',
        img_prefix='data/mixture/icdar_2013/',
        ann_file='data/mixture/icdar_2013/test_label_1015.txt',
        loader=dict(
            type='AnnFileLoader',
            repeat=1,
            file_format='txt',
            parser=dict(
                type='LineStrParser',
                keys=['filename', 'text'],
                keys_idx=[0, 1],
                separator=' ')),
        pipeline=None,
        test_mode=True),
    dict(
        type='OCRDataset',
        img_prefix='data/mixture/icdar_2015/',
        ann_file='data/mixture/icdar_2015/test_label.txt',
        loader=dict(
            type='AnnFileLoader',
            repeat=1,
            file_format='txt',
            parser=dict(
                type='LineStrParser',
                keys=['filename', 'text'],
                keys_idx=[0, 1],
                separator=' ')),
        pipeline=None,
        test_mode=True),
    dict(
        type='OCRDataset',
        img_prefix='data/mixture/svtp/',
        ann_file='data/mixture/svtp/test_label.txt',
        loader=dict(
            type='AnnFileLoader',
            repeat=1,
            file_format='txt',
            parser=dict(
                type='LineStrParser',
                keys=['filename', 'text'],
                keys_idx=[0, 1],
                separator=' ')),
        pipeline=None,
        test_mode=True),
    dict(
        type='OCRDataset',
        img_prefix='data/mixture/ct80/',
        ann_file='data/mixture/ct80/test_label.txt',
        loader=dict(
            type='AnnFileLoader',
            repeat=1,
            file_format='txt',
            parser=dict(
                type='LineStrParser',
                keys=['filename', 'text'],
                keys_idx=[0, 1],
                separator=' ')),
        pipeline=None,
        test_mode=True),
    dict(
        type='OCRDataset',
        img_prefix='data/mixture/WordArt/',
        ann_file='data/mixture/WordArt/test_label.txt',
        loader=dict(
            type='AnnFileLoader',
            repeat=1,
            file_format='txt',
            parser=dict(
                type='LineStrParser',
                keys=['filename', 'text'],
                keys_idx=[0, 1],
                separator=' ')),
        pipeline=None,
        test_mode=True)
]
label_convertor = dict(
    type='AttnConvertor', dict_type='DICT90', with_unknown=True)
model = dict(
    type='CornerTransformer',
    preprocessor=dict(type='CornerPreprocessor'),
    backbone=dict(type='ShallowCNN', input_channels=3, hidden_dim=512),
    backbone_corner=dict(type='ShallowCNN', input_channels=1, hidden_dim=512),
    encoder=dict(
        type='CornerEncoder',
        n_layers=12,
        n_head=8,
        d_k=64,
        d_v=64,
        d_model=512,
        n_position=100,
        d_inner=2048,
        dropout=0.1),
    decoder=dict(
        type='CharContDecoder',
        n_layers=6,
        d_embedding=512,
        n_head=8,
        d_model=512,
        d_inner=2048,
        d_k=64,
        d_v=64),
    loss=dict(type='TFLoss'),
    label_convertor=dict(
        type='AttnConvertor', dict_type='DICT90', with_unknown=True),
    max_seq_len=25)
optimizer = dict(type='Adam', lr=0.0003)
optimizer_config = dict(grad_clip=None)
lr_config = dict(policy='step', step=[4])
total_epochs = 6
data = dict(
    samples_per_gpu=64,
    workers_per_gpu=4,
    val_dataloader=dict(samples_per_gpu=1),
    test_dataloader=dict(samples_per_gpu=1),
    train=dict(
        type='UniformConcatDataset',
        datasets=[
            dict(
                type='OCRDataset',
                img_prefix='data/mixture/Syn90k/mnt/ramdisk/max/90kDICT32px',
                ann_file='data/mixture/Syn90k/label.lmdb',
                loader=dict(
                    type='AnnFileLoader',
                    repeat=1,
                    file_format='lmdb',
                    parser=dict(
                        type='LineJsonParser', keys=['filename', 'text'])),
                pipeline=None,
                test_mode=False),
            dict(
                type='OCRDataset',
                img_prefix=
                'data/mixture/SynthText/synthtext/SynthText_patch_horizontal',
                ann_file='data/mixture/SynthText/label.lmdb',
                loader=dict(
                    type='AnnFileLoader',
                    repeat=1,
                    file_format='lmdb',
                    parser=dict(
                        type='LineJsonParser', keys=['filename', 'text'])),
                pipeline=None,
                test_mode=False)
        ],
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='ResizeOCR',
                height=32,
                min_width=128,
                max_width=128,
                keep_aspect_ratio=False,
                width_downsample_ratio=0.25),
            dict(
                type='RandomWrapper',
                p=0.5,
                transforms=[
                    dict(
                        type='OneOfWrapper',
                        transforms=[
                            dict(type='RandomRotateTextDet', max_angle=15),
                            dict(
                                type='TorchVisionWrapper',
                                op='RandomAffine',
                                degrees=15,
                                translate=(0.3, 0.3),
                                scale=(0.5, 2.0),
                                shear=(-45, 45)),
                            dict(
                                type='TorchVisionWrapper',
                                op='RandomPerspective',
                                distortion_scale=0.5,
                                p=1)
                        ])
                ]),
            dict(
                type='RandomWrapper',
                p=0.25,
                transforms=[
                    dict(type='PyramidRescale'),
                    dict(
                        type='Albu',
                        transforms=[
                            dict(type='GaussNoise', var_limit=(20, 20), p=0.5),
                            dict(type='MotionBlur', blur_limit=6, p=0.5)
                        ])
                ]),
            dict(
                type='RandomWrapper',
                p=0.25,
                transforms=[
                    dict(
                        type='TorchVisionWrapper',
                        op='ColorJitter',
                        brightness=0.5,
                        saturation=0.5,
                        contrast=0.5,
                        hue=0.1)
                ]),
            dict(type='ToTensorOCR'),
            dict(
                type='NormalizeOCR',
                mean=[0.485, 0.456, 0.406],
                std=[0.229, 0.224, 0.225]),
            dict(
                type='Collect',
                keys=['img'],
                meta_keys=[
                    'filename', 'ori_shape', 'img_shape', 'text',
                    'valid_ratio', 'resize_shape', 'img_norm_cfg'
                ])
        ]),
    val=dict(
        type='UniformConcatDataset',
        datasets=[
            dict(
                type='OCRDataset',
                img_prefix='data/mixture/IIIT5K/',
                ann_file='data/mixture/IIIT5K/test_label.txt',
                loader=dict(
                    type='AnnFileLoader',
                    repeat=1,
                    file_format='txt',
                    parser=dict(
                        type='LineStrParser',
                        keys=['filename', 'text'],
                        keys_idx=[0, 1],
                        separator=' ')),
                pipeline=None,
                test_mode=True),
            dict(
                type='OCRDataset',
                img_prefix='data/mixture/svt/',
                ann_file='data/mixture/svt/test_label.txt',
                loader=dict(
                    type='AnnFileLoader',
                    repeat=1,
                    file_format='txt',
                    parser=dict(
                        type='LineStrParser',
                        keys=['filename', 'text'],
                        keys_idx=[0, 1],
                        separator=' ')),
                pipeline=None,
                test_mode=True),
            dict(
                type='OCRDataset',
                img_prefix='data/mixture/icdar_2013/',
                ann_file='data/mixture/icdar_2013/test_label_1015.txt',
                loader=dict(
                    type='AnnFileLoader',
                    repeat=1,
                    file_format='txt',
                    parser=dict(
                        type='LineStrParser',
                        keys=['filename', 'text'],
                        keys_idx=[0, 1],
                        separator=' ')),
                pipeline=None,
                test_mode=True),
            dict(
                type='OCRDataset',
                img_prefix='data/mixture/icdar_2015/',
                ann_file='data/mixture/icdar_2015/test_label.txt',
                loader=dict(
                    type='AnnFileLoader',
                    repeat=1,
                    file_format='txt',
                    parser=dict(
                        type='LineStrParser',
                        keys=['filename', 'text'],
                        keys_idx=[0, 1],
                        separator=' ')),
                pipeline=None,
                test_mode=True),
            dict(
                type='OCRDataset',
                img_prefix='data/mixture/svtp/',
                ann_file='data/mixture/svtp/test_label.txt',
                loader=dict(
                    type='AnnFileLoader',
                    repeat=1,
                    file_format='txt',
                    parser=dict(
                        type='LineStrParser',
                        keys=['filename', 'text'],
                        keys_idx=[0, 1],
                        separator=' ')),
                pipeline=None,
                test_mode=True),
            dict(
                type='OCRDataset',
                img_prefix='data/mixture/ct80/',
                ann_file='data/mixture/ct80/test_label.txt',
                loader=dict(
                    type='AnnFileLoader',
                    repeat=1,
                    file_format='txt',
                    parser=dict(
                        type='LineStrParser',
                        keys=['filename', 'text'],
                        keys_idx=[0, 1],
                        separator=' ')),
                pipeline=None,
                test_mode=True),
            dict(
                type='OCRDataset',
                img_prefix='data/mixture/WordArt/',
                ann_file='data/mixture/WordArt/test_label.txt',
                loader=dict(
                    type='AnnFileLoader',
                    repeat=1,
                    file_format='txt',
                    parser=dict(
                        type='LineStrParser',
                        keys=['filename', 'text'],
                        keys_idx=[0, 1],
                        separator=' ')),
                pipeline=None,
                test_mode=True)
        ],
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiRotateAugOCR',
                rotate_degrees=[0, 90, 270],
                transforms=[
                    dict(
                        type='ResizeOCR',
                        height=32,
                        min_width=128,
                        max_width=128,
                        keep_aspect_ratio=False,
                        width_downsample_ratio=0.25),
                    dict(type='ToTensorOCR'),
                    dict(
                        type='NormalizeOCR',
                        mean=[0.485, 0.456, 0.406],
                        std=[0.229, 0.224, 0.225]),
                    dict(
                        type='Collect',
                        keys=['img'],
                        meta_keys=[
                            'filename', 'ori_shape', 'img_shape',
                            'valid_ratio', 'resize_shape', 'img_norm_cfg',
                            'ori_filename'
                        ])
                ])
        ]),
    test=dict(
        type='UniformConcatDataset',
        datasets=[
            dict(
                type='OCRDataset',
                img_prefix='data/mixture/IIIT5K/',
                ann_file='data/mixture/IIIT5K/test_label.txt',
                loader=dict(
                    type='AnnFileLoader',
                    repeat=1,
                    file_format='txt',
                    parser=dict(
                        type='LineStrParser',
                        keys=['filename', 'text'],
                        keys_idx=[0, 1],
                        separator=' ')),
                pipeline=None,
                test_mode=True),
            dict(
                type='OCRDataset',
                img_prefix='data/mixture/svt/',
                ann_file='data/mixture/svt/test_label.txt',
                loader=dict(
                    type='AnnFileLoader',
                    repeat=1,
                    file_format='txt',
                    parser=dict(
                        type='LineStrParser',
                        keys=['filename', 'text'],
                        keys_idx=[0, 1],
                        separator=' ')),
                pipeline=None,
                test_mode=True),
            dict(
                type='OCRDataset',
                img_prefix='data/mixture/icdar_2013/',
                ann_file='data/mixture/icdar_2013/test_label_1015.txt',
                loader=dict(
                    type='AnnFileLoader',
                    repeat=1,
                    file_format='txt',
                    parser=dict(
                        type='LineStrParser',
                        keys=['filename', 'text'],
                        keys_idx=[0, 1],
                        separator=' ')),
                pipeline=None,
                test_mode=True),
            dict(
                type='OCRDataset',
                img_prefix='data/mixture/icdar_2015/',
                ann_file='data/mixture/icdar_2015/test_label.txt',
                loader=dict(
                    type='AnnFileLoader',
                    repeat=1,
                    file_format='txt',
                    parser=dict(
                        type='LineStrParser',
                        keys=['filename', 'text'],
                        keys_idx=[0, 1],
                        separator=' ')),
                pipeline=None,
                test_mode=True),
            dict(
                type='OCRDataset',
                img_prefix='data/mixture/svtp/',
                ann_file='data/mixture/svtp/test_label.txt',
                loader=dict(
                    type='AnnFileLoader',
                    repeat=1,
                    file_format='txt',
                    parser=dict(
                        type='LineStrParser',
                        keys=['filename', 'text'],
                        keys_idx=[0, 1],
                        separator=' ')),
                pipeline=None,
                test_mode=True),
            dict(
                type='OCRDataset',
                img_prefix='data/mixture/ct80/',
                ann_file='data/mixture/ct80/test_label.txt',
                loader=dict(
                    type='AnnFileLoader',
                    repeat=1,
                    file_format='txt',
                    parser=dict(
                        type='LineStrParser',
                        keys=['filename', 'text'],
                        keys_idx=[0, 1],
                        separator=' ')),
                pipeline=None,
                test_mode=True),
            dict(
                type='OCRDataset',
                img_prefix='data/mixture/WordArt/',
                ann_file='data/mixture/WordArt/test_label.txt',
                loader=dict(
                    type='AnnFileLoader',
                    repeat=1,
                    file_format='txt',
                    parser=dict(
                        type='LineStrParser',
                        keys=['filename', 'text'],
                        keys_idx=[0, 1],
                        separator=' ')),
                pipeline=None,
                test_mode=True)
        ],
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiRotateAugOCR',
                rotate_degrees=[0, 90, 270],
                transforms=[
                    dict(
                        type='ResizeOCR',
                        height=32,
                        min_width=128,
                        max_width=128,
                        keep_aspect_ratio=False,
                        width_downsample_ratio=0.25),
                    dict(type='ToTensorOCR'),
                    dict(
                        type='NormalizeOCR',
                        mean=[0.485, 0.456, 0.406],
                        std=[0.229, 0.224, 0.225]),
                    dict(
                        type='Collect',
                        keys=['img'],
                        meta_keys=[
                            'filename', 'ori_shape', 'img_shape',
                            'valid_ratio', 'resize_shape', 'img_norm_cfg',
                            'ori_filename'
                        ])
                ])
        ]))
evaluation = dict(interval=1, metric='acc')
work_dir = 'outputs/corner_transformer'
gpu_ids = range(0, 2)

2022-07-21 02:03:39,185 - mmocr - INFO - Set random seed to 0, deterministic: False
2022-07-21 02:03:40,008 - mmocr - INFO - initialize ShallowCNN with init_cfg [{'type': 'Kaiming', 'layer': 'Conv2d'}, {'type': 'Uniform', 'layer': 'BatchNorm2d'}]
2022-07-21 02:03:40,025 - mmocr - INFO - initialize ShallowCNN with init_cfg [{'type': 'Kaiming', 'layer': 'Conv2d'}, {'type': 'Uniform', 'layer': 'BatchNorm2d'}]
2022-07-21 02:03:40,040 - mmocr - INFO - initialize Adaptive2DPositionalEncoding with init_cfg [{'type': 'Xavier', 'layer': 'Conv2d'}]
2022-07-21 02:03:40,048 - mmocr - INFO - initialize Adaptive2DPositionalEncoding with init_cfg [{'type': 'Xavier', 'layer': 'Conv2d'}]
2022-07-21 02:03:40,056 - mmocr - INFO - initialize LocalityAwareFeedforward with init_cfg [{'type': 'Xavier', 'layer': 'Conv2d'}, {'type': 'Constant', 'layer': 'BatchNorm2d', 'val': 1, 'bias': 0}]
2022-07-21 02:03:40,086 - mmocr - INFO - initialize LocalityAwareFeedforward with init_cfg [{'type': 'Xavier', 'layer': 'Conv2d'}, {'type': 'Constant', 'layer': 'BatchNorm2d', 'val': 1, 'bias': 0}]
2022-07-21 02:03:40,115 - mmocr - INFO - initialize LocalityAwareFeedforward with init_cfg [{'type': 'Xavier', 'layer': 'Conv2d'}, {'type': 'Constant', 'layer': 'BatchNorm2d', 'val': 1, 'bias': 0}]
2022-07-21 02:03:40,145 - mmocr - INFO - initialize LocalityAwareFeedforward with init_cfg [{'type': 'Xavier', 'layer': 'Conv2d'}, {'type': 'Constant', 'layer': 'BatchNorm2d', 'val': 1, 'bias': 0}]
2022-07-21 02:03:40,175 - mmocr - INFO - initialize LocalityAwareFeedforward with init_cfg [{'type': 'Xavier', 'layer': 'Conv2d'}, {'type': 'Constant', 'layer': 'BatchNorm2d', 'val': 1, 'bias': 0}]
2022-07-21 02:03:40,204 - mmocr - INFO - initialize LocalityAwareFeedforward with init_cfg [{'type': 'Xavier', 'layer': 'Conv2d'}, {'type': 'Constant', 'layer': 'BatchNorm2d', 'val': 1, 'bias': 0}]
2022-07-21 02:03:40,234 - mmocr - INFO - initialize LocalityAwareFeedforward with init_cfg [{'type': 'Xavier', 'layer': 'Conv2d'}, {'type': 'Constant', 'layer': 'BatchNorm2d', 'val': 1, 'bias': 0}]
2022-07-21 02:03:40,264 - mmocr - INFO - initialize LocalityAwareFeedforward with init_cfg [{'type': 'Xavier', 'layer': 'Conv2d'}, {'type': 'Constant', 'layer': 'BatchNorm2d', 'val': 1, 'bias': 0}]
2022-07-21 02:03:40,294 - mmocr - INFO - initialize LocalityAwareFeedforward with init_cfg [{'type': 'Xavier', 'layer': 'Conv2d'}, {'type': 'Constant', 'layer': 'BatchNorm2d', 'val': 1, 'bias': 0}]
2022-07-21 02:03:40,324 - mmocr - INFO - initialize LocalityAwareFeedforward with init_cfg [{'type': 'Xavier', 'layer': 'Conv2d'}, {'type': 'Constant', 'layer': 'BatchNorm2d', 'val': 1, 'bias': 0}]
2022-07-21 02:03:40,355 - mmocr - INFO - initialize LocalityAwareFeedforward with init_cfg [{'type': 'Xavier', 'layer': 'Conv2d'}, {'type': 'Constant', 'layer': 'BatchNorm2d', 'val': 1, 'bias': 0}]
2022-07-21 02:03:40,385 - mmocr - INFO - initialize LocalityAwareFeedforward with init_cfg [{'type': 'Xavier', 'layer': 'Conv2d'}, {'type': 'Constant', 'layer': 'BatchNorm2d', 'val': 1, 'bias': 0}]
Name of parameter - Initialization information

backbone.conv1.conv.weight - torch.Size([256, 3, 3, 3]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.conv1.bn.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.conv1.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

backbone.conv2.conv.weight - torch.Size([512, 256, 3, 3]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.conv2.bn.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone.conv2.bn.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

backbone_corner.conv1.conv.weight - torch.Size([256, 1, 3, 3]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone_corner.conv1.bn.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone_corner.conv1.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

backbone_corner.conv2.conv.weight - torch.Size([512, 256, 3, 3]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone_corner.conv2.bn.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in ConvModule  

backbone_corner.conv2.bn.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.position_enc.h_scale.0.weight - torch.Size([512, 512, 1, 1]): 
XavierInit: gain=1, distribution=normal, bias=0 

encoder.position_enc.h_scale.0.bias - torch.Size([512]): 
XavierInit: gain=1, distribution=normal, bias=0 

encoder.position_enc.h_scale.2.weight - torch.Size([512, 512, 1, 1]): 
XavierInit: gain=1, distribution=normal, bias=0 

encoder.position_enc.h_scale.2.bias - torch.Size([512]): 
XavierInit: gain=1, distribution=normal, bias=0 

encoder.position_enc.w_scale.0.weight - torch.Size([512, 512, 1, 1]): 
XavierInit: gain=1, distribution=normal, bias=0 

encoder.position_enc.w_scale.0.bias - torch.Size([512]): 
XavierInit: gain=1, distribution=normal, bias=0 

encoder.position_enc.w_scale.2.weight - torch.Size([512, 512, 1, 1]): 
XavierInit: gain=1, distribution=normal, bias=0 

encoder.position_enc.w_scale.2.bias - torch.Size([512]): 
XavierInit: gain=1, distribution=normal, bias=0 

encoder.position_enc_corner.h_scale.0.weight - torch.Size([512, 512, 1, 1]): 
XavierInit: gain=1, distribution=normal, bias=0 

encoder.position_enc_corner.h_scale.0.bias - torch.Size([512]): 
XavierInit: gain=1, distribution=normal, bias=0 

encoder.position_enc_corner.h_scale.2.weight - torch.Size([512, 512, 1, 1]): 
XavierInit: gain=1, distribution=normal, bias=0 

encoder.position_enc_corner.h_scale.2.bias - torch.Size([512]): 
XavierInit: gain=1, distribution=normal, bias=0 

encoder.position_enc_corner.w_scale.0.weight - torch.Size([512, 512, 1, 1]): 
XavierInit: gain=1, distribution=normal, bias=0 

encoder.position_enc_corner.w_scale.0.bias - torch.Size([512]): 
XavierInit: gain=1, distribution=normal, bias=0 

encoder.position_enc_corner.w_scale.2.weight - torch.Size([512, 512, 1, 1]): 
XavierInit: gain=1, distribution=normal, bias=0 

encoder.position_enc_corner.w_scale.2.bias - torch.Size([512]): 
XavierInit: gain=1, distribution=normal, bias=0 

encoder.layer_stack.0.norm1.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.0.norm1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.0.attn.linear_q.weight - torch.Size([512, 512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.0.attn.linear_k.weight - torch.Size([512, 512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.0.attn.linear_v.weight - torch.Size([512, 512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.0.attn.fc.weight - torch.Size([512, 512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.0.corner_attn.linear_q.weight - torch.Size([512, 512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.0.corner_attn.linear_k.weight - torch.Size([512, 512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.0.corner_attn.linear_v.weight - torch.Size([512, 512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.0.corner_attn.fc.weight - torch.Size([512, 512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.0.norm2.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.0.norm2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.0.norm3.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.0.norm3.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.0.feed_forward.conv1.conv.weight - torch.Size([2048, 512, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

encoder.layer_stack.0.feed_forward.conv1.bn.weight - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.0.feed_forward.conv1.bn.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.0.feed_forward.depthwise_conv.conv.weight - torch.Size([2048, 1, 3, 3]): 
Initialized by user-defined `init_weights` in ConvModule  

encoder.layer_stack.0.feed_forward.depthwise_conv.bn.weight - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.0.feed_forward.depthwise_conv.bn.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.0.feed_forward.conv2.conv.weight - torch.Size([512, 2048, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

encoder.layer_stack.0.feed_forward.conv2.bn.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.0.feed_forward.conv2.bn.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.1.norm1.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.1.norm1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.1.attn.linear_q.weight - torch.Size([512, 512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.1.attn.linear_k.weight - torch.Size([512, 512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.1.attn.linear_v.weight - torch.Size([512, 512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.1.attn.fc.weight - torch.Size([512, 512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.1.corner_attn.linear_q.weight - torch.Size([512, 512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.1.corner_attn.linear_k.weight - torch.Size([512, 512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.1.corner_attn.linear_v.weight - torch.Size([512, 512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.1.corner_attn.fc.weight - torch.Size([512, 512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.1.norm2.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.1.norm2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.1.norm3.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.1.norm3.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.1.feed_forward.conv1.conv.weight - torch.Size([2048, 512, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

encoder.layer_stack.1.feed_forward.conv1.bn.weight - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.1.feed_forward.conv1.bn.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.1.feed_forward.depthwise_conv.conv.weight - torch.Size([2048, 1, 3, 3]): 
Initialized by user-defined `init_weights` in ConvModule  

encoder.layer_stack.1.feed_forward.depthwise_conv.bn.weight - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.1.feed_forward.depthwise_conv.bn.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.1.feed_forward.conv2.conv.weight - torch.Size([512, 2048, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

encoder.layer_stack.1.feed_forward.conv2.bn.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.1.feed_forward.conv2.bn.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.2.norm1.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.2.norm1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.2.attn.linear_q.weight - torch.Size([512, 512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.2.attn.linear_k.weight - torch.Size([512, 512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.2.attn.linear_v.weight - torch.Size([512, 512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.2.attn.fc.weight - torch.Size([512, 512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.2.corner_attn.linear_q.weight - torch.Size([512, 512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.2.corner_attn.linear_k.weight - torch.Size([512, 512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.2.corner_attn.linear_v.weight - torch.Size([512, 512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.2.corner_attn.fc.weight - torch.Size([512, 512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.2.norm2.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.2.norm2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.2.norm3.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.2.norm3.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.2.feed_forward.conv1.conv.weight - torch.Size([2048, 512, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

encoder.layer_stack.2.feed_forward.conv1.bn.weight - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.2.feed_forward.conv1.bn.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.2.feed_forward.depthwise_conv.conv.weight - torch.Size([2048, 1, 3, 3]): 
Initialized by user-defined `init_weights` in ConvModule  

encoder.layer_stack.2.feed_forward.depthwise_conv.bn.weight - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.2.feed_forward.depthwise_conv.bn.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.2.feed_forward.conv2.conv.weight - torch.Size([512, 2048, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

encoder.layer_stack.2.feed_forward.conv2.bn.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.2.feed_forward.conv2.bn.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.3.norm1.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.3.norm1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.3.attn.linear_q.weight - torch.Size([512, 512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.3.attn.linear_k.weight - torch.Size([512, 512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.3.attn.linear_v.weight - torch.Size([512, 512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.3.attn.fc.weight - torch.Size([512, 512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.3.corner_attn.linear_q.weight - torch.Size([512, 512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.3.corner_attn.linear_k.weight - torch.Size([512, 512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.3.corner_attn.linear_v.weight - torch.Size([512, 512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.3.corner_attn.fc.weight - torch.Size([512, 512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.3.norm2.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.3.norm2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.3.norm3.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.3.norm3.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.3.feed_forward.conv1.conv.weight - torch.Size([2048, 512, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

encoder.layer_stack.3.feed_forward.conv1.bn.weight - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.3.feed_forward.conv1.bn.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.3.feed_forward.depthwise_conv.conv.weight - torch.Size([2048, 1, 3, 3]): 
Initialized by user-defined `init_weights` in ConvModule  

encoder.layer_stack.3.feed_forward.depthwise_conv.bn.weight - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.3.feed_forward.depthwise_conv.bn.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.3.feed_forward.conv2.conv.weight - torch.Size([512, 2048, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

encoder.layer_stack.3.feed_forward.conv2.bn.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.3.feed_forward.conv2.bn.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.4.norm1.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.4.norm1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.4.attn.linear_q.weight - torch.Size([512, 512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.4.attn.linear_k.weight - torch.Size([512, 512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.4.attn.linear_v.weight - torch.Size([512, 512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.4.attn.fc.weight - torch.Size([512, 512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.4.corner_attn.linear_q.weight - torch.Size([512, 512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.4.corner_attn.linear_k.weight - torch.Size([512, 512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.4.corner_attn.linear_v.weight - torch.Size([512, 512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.4.corner_attn.fc.weight - torch.Size([512, 512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.4.norm2.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.4.norm2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.4.norm3.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.4.norm3.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.4.feed_forward.conv1.conv.weight - torch.Size([2048, 512, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

encoder.layer_stack.4.feed_forward.conv1.bn.weight - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.4.feed_forward.conv1.bn.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.4.feed_forward.depthwise_conv.conv.weight - torch.Size([2048, 1, 3, 3]): 
Initialized by user-defined `init_weights` in ConvModule  

encoder.layer_stack.4.feed_forward.depthwise_conv.bn.weight - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.4.feed_forward.depthwise_conv.bn.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.4.feed_forward.conv2.conv.weight - torch.Size([512, 2048, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

encoder.layer_stack.4.feed_forward.conv2.bn.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.4.feed_forward.conv2.bn.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.5.norm1.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.5.norm1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.5.attn.linear_q.weight - torch.Size([512, 512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.5.attn.linear_k.weight - torch.Size([512, 512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.5.attn.linear_v.weight - torch.Size([512, 512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.5.attn.fc.weight - torch.Size([512, 512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.5.corner_attn.linear_q.weight - torch.Size([512, 512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.5.corner_attn.linear_k.weight - torch.Size([512, 512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.5.corner_attn.linear_v.weight - torch.Size([512, 512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.5.corner_attn.fc.weight - torch.Size([512, 512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.5.norm2.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.5.norm2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.5.norm3.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.5.norm3.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.5.feed_forward.conv1.conv.weight - torch.Size([2048, 512, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

encoder.layer_stack.5.feed_forward.conv1.bn.weight - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.5.feed_forward.conv1.bn.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.5.feed_forward.depthwise_conv.conv.weight - torch.Size([2048, 1, 3, 3]): 
Initialized by user-defined `init_weights` in ConvModule  

encoder.layer_stack.5.feed_forward.depthwise_conv.bn.weight - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.5.feed_forward.depthwise_conv.bn.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.5.feed_forward.conv2.conv.weight - torch.Size([512, 2048, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

encoder.layer_stack.5.feed_forward.conv2.bn.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.5.feed_forward.conv2.bn.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.6.norm1.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.6.norm1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.6.attn.linear_q.weight - torch.Size([512, 512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.6.attn.linear_k.weight - torch.Size([512, 512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.6.attn.linear_v.weight - torch.Size([512, 512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.6.attn.fc.weight - torch.Size([512, 512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.6.corner_attn.linear_q.weight - torch.Size([512, 512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.6.corner_attn.linear_k.weight - torch.Size([512, 512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.6.corner_attn.linear_v.weight - torch.Size([512, 512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.6.corner_attn.fc.weight - torch.Size([512, 512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.6.norm2.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.6.norm2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.6.norm3.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.6.norm3.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.6.feed_forward.conv1.conv.weight - torch.Size([2048, 512, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

encoder.layer_stack.6.feed_forward.conv1.bn.weight - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.6.feed_forward.conv1.bn.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.6.feed_forward.depthwise_conv.conv.weight - torch.Size([2048, 1, 3, 3]): 
Initialized by user-defined `init_weights` in ConvModule  

encoder.layer_stack.6.feed_forward.depthwise_conv.bn.weight - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.6.feed_forward.depthwise_conv.bn.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.6.feed_forward.conv2.conv.weight - torch.Size([512, 2048, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

encoder.layer_stack.6.feed_forward.conv2.bn.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.6.feed_forward.conv2.bn.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.7.norm1.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.7.norm1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.7.attn.linear_q.weight - torch.Size([512, 512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.7.attn.linear_k.weight - torch.Size([512, 512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.7.attn.linear_v.weight - torch.Size([512, 512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.7.attn.fc.weight - torch.Size([512, 512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.7.corner_attn.linear_q.weight - torch.Size([512, 512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.7.corner_attn.linear_k.weight - torch.Size([512, 512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.7.corner_attn.linear_v.weight - torch.Size([512, 512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.7.corner_attn.fc.weight - torch.Size([512, 512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.7.norm2.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.7.norm2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.7.norm3.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.7.norm3.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.7.feed_forward.conv1.conv.weight - torch.Size([2048, 512, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

encoder.layer_stack.7.feed_forward.conv1.bn.weight - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.7.feed_forward.conv1.bn.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.7.feed_forward.depthwise_conv.conv.weight - torch.Size([2048, 1, 3, 3]): 
Initialized by user-defined `init_weights` in ConvModule  

encoder.layer_stack.7.feed_forward.depthwise_conv.bn.weight - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.7.feed_forward.depthwise_conv.bn.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.7.feed_forward.conv2.conv.weight - torch.Size([512, 2048, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

encoder.layer_stack.7.feed_forward.conv2.bn.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.7.feed_forward.conv2.bn.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.8.norm1.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.8.norm1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.8.attn.linear_q.weight - torch.Size([512, 512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.8.attn.linear_k.weight - torch.Size([512, 512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.8.attn.linear_v.weight - torch.Size([512, 512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.8.attn.fc.weight - torch.Size([512, 512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.8.corner_attn.linear_q.weight - torch.Size([512, 512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.8.corner_attn.linear_k.weight - torch.Size([512, 512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.8.corner_attn.linear_v.weight - torch.Size([512, 512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.8.corner_attn.fc.weight - torch.Size([512, 512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.8.norm2.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.8.norm2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.8.norm3.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.8.norm3.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.8.feed_forward.conv1.conv.weight - torch.Size([2048, 512, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

encoder.layer_stack.8.feed_forward.conv1.bn.weight - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.8.feed_forward.conv1.bn.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.8.feed_forward.depthwise_conv.conv.weight - torch.Size([2048, 1, 3, 3]): 
Initialized by user-defined `init_weights` in ConvModule  

encoder.layer_stack.8.feed_forward.depthwise_conv.bn.weight - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.8.feed_forward.depthwise_conv.bn.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.8.feed_forward.conv2.conv.weight - torch.Size([512, 2048, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

encoder.layer_stack.8.feed_forward.conv2.bn.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.8.feed_forward.conv2.bn.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.9.norm1.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.9.norm1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.9.attn.linear_q.weight - torch.Size([512, 512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.9.attn.linear_k.weight - torch.Size([512, 512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.9.attn.linear_v.weight - torch.Size([512, 512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.9.attn.fc.weight - torch.Size([512, 512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.9.corner_attn.linear_q.weight - torch.Size([512, 512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.9.corner_attn.linear_k.weight - torch.Size([512, 512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.9.corner_attn.linear_v.weight - torch.Size([512, 512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.9.corner_attn.fc.weight - torch.Size([512, 512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.9.norm2.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.9.norm2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.9.norm3.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.9.norm3.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.9.feed_forward.conv1.conv.weight - torch.Size([2048, 512, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

encoder.layer_stack.9.feed_forward.conv1.bn.weight - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.9.feed_forward.conv1.bn.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.9.feed_forward.depthwise_conv.conv.weight - torch.Size([2048, 1, 3, 3]): 
Initialized by user-defined `init_weights` in ConvModule  

encoder.layer_stack.9.feed_forward.depthwise_conv.bn.weight - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.9.feed_forward.depthwise_conv.bn.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.9.feed_forward.conv2.conv.weight - torch.Size([512, 2048, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

encoder.layer_stack.9.feed_forward.conv2.bn.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.9.feed_forward.conv2.bn.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.10.norm1.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.10.norm1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.10.attn.linear_q.weight - torch.Size([512, 512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.10.attn.linear_k.weight - torch.Size([512, 512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.10.attn.linear_v.weight - torch.Size([512, 512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.10.attn.fc.weight - torch.Size([512, 512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.10.corner_attn.linear_q.weight - torch.Size([512, 512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.10.corner_attn.linear_k.weight - torch.Size([512, 512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.10.corner_attn.linear_v.weight - torch.Size([512, 512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.10.corner_attn.fc.weight - torch.Size([512, 512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.10.norm2.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.10.norm2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.10.norm3.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.10.norm3.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.10.feed_forward.conv1.conv.weight - torch.Size([2048, 512, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

encoder.layer_stack.10.feed_forward.conv1.bn.weight - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.10.feed_forward.conv1.bn.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.10.feed_forward.depthwise_conv.conv.weight - torch.Size([2048, 1, 3, 3]): 
Initialized by user-defined `init_weights` in ConvModule  

encoder.layer_stack.10.feed_forward.depthwise_conv.bn.weight - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.10.feed_forward.depthwise_conv.bn.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.10.feed_forward.conv2.conv.weight - torch.Size([512, 2048, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

encoder.layer_stack.10.feed_forward.conv2.bn.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.10.feed_forward.conv2.bn.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.11.norm1.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.11.norm1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.11.attn.linear_q.weight - torch.Size([512, 512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.11.attn.linear_k.weight - torch.Size([512, 512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.11.attn.linear_v.weight - torch.Size([512, 512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.11.attn.fc.weight - torch.Size([512, 512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.11.corner_attn.linear_q.weight - torch.Size([512, 512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.11.corner_attn.linear_k.weight - torch.Size([512, 512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.11.corner_attn.linear_v.weight - torch.Size([512, 512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.11.corner_attn.fc.weight - torch.Size([512, 512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.11.norm2.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.11.norm2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.11.norm3.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.11.norm3.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.11.feed_forward.conv1.conv.weight - torch.Size([2048, 512, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

encoder.layer_stack.11.feed_forward.conv1.bn.weight - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.11.feed_forward.conv1.bn.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.11.feed_forward.depthwise_conv.conv.weight - torch.Size([2048, 1, 3, 3]): 
Initialized by user-defined `init_weights` in ConvModule  

encoder.layer_stack.11.feed_forward.depthwise_conv.bn.weight - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.11.feed_forward.depthwise_conv.bn.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.11.feed_forward.conv2.conv.weight - torch.Size([512, 2048, 1, 1]): 
Initialized by user-defined `init_weights` in ConvModule  

encoder.layer_stack.11.feed_forward.conv2.bn.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_stack.11.feed_forward.conv2.bn.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_norm.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

encoder.layer_norm.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

decoder.trg_word_emb.weight - torch.Size([93, 512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

decoder.layer_stack.0.norm1.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

decoder.layer_stack.0.norm1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

decoder.layer_stack.0.norm2.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

decoder.layer_stack.0.norm2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

decoder.layer_stack.0.norm3.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

decoder.layer_stack.0.norm3.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

decoder.layer_stack.0.self_attn.linear_q.weight - torch.Size([512, 512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

decoder.layer_stack.0.self_attn.linear_k.weight - torch.Size([512, 512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

decoder.layer_stack.0.self_attn.linear_v.weight - torch.Size([512, 512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

decoder.layer_stack.0.self_attn.fc.weight - torch.Size([512, 512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

decoder.layer_stack.0.enc_attn.linear_q.weight - torch.Size([512, 512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

decoder.layer_stack.0.enc_attn.linear_k.weight - torch.Size([512, 512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

decoder.layer_stack.0.enc_attn.linear_v.weight - torch.Size([512, 512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

decoder.layer_stack.0.enc_attn.fc.weight - torch.Size([512, 512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

decoder.layer_stack.0.mlp.w_1.weight - torch.Size([2048, 512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

decoder.layer_stack.0.mlp.w_1.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

decoder.layer_stack.0.mlp.w_2.weight - torch.Size([512, 2048]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

decoder.layer_stack.0.mlp.w_2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

decoder.layer_stack.1.norm1.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

decoder.layer_stack.1.norm1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

decoder.layer_stack.1.norm2.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

decoder.layer_stack.1.norm2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

decoder.layer_stack.1.norm3.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

decoder.layer_stack.1.norm3.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

decoder.layer_stack.1.self_attn.linear_q.weight - torch.Size([512, 512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

decoder.layer_stack.1.self_attn.linear_k.weight - torch.Size([512, 512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

decoder.layer_stack.1.self_attn.linear_v.weight - torch.Size([512, 512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

decoder.layer_stack.1.self_attn.fc.weight - torch.Size([512, 512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

decoder.layer_stack.1.enc_attn.linear_q.weight - torch.Size([512, 512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

decoder.layer_stack.1.enc_attn.linear_k.weight - torch.Size([512, 512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

decoder.layer_stack.1.enc_attn.linear_v.weight - torch.Size([512, 512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

decoder.layer_stack.1.enc_attn.fc.weight - torch.Size([512, 512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

decoder.layer_stack.1.mlp.w_1.weight - torch.Size([2048, 512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

decoder.layer_stack.1.mlp.w_1.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

decoder.layer_stack.1.mlp.w_2.weight - torch.Size([512, 2048]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

decoder.layer_stack.1.mlp.w_2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

decoder.layer_stack.2.norm1.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

decoder.layer_stack.2.norm1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

decoder.layer_stack.2.norm2.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

decoder.layer_stack.2.norm2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

decoder.layer_stack.2.norm3.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

decoder.layer_stack.2.norm3.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

decoder.layer_stack.2.self_attn.linear_q.weight - torch.Size([512, 512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

decoder.layer_stack.2.self_attn.linear_k.weight - torch.Size([512, 512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

decoder.layer_stack.2.self_attn.linear_v.weight - torch.Size([512, 512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

decoder.layer_stack.2.self_attn.fc.weight - torch.Size([512, 512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

decoder.layer_stack.2.enc_attn.linear_q.weight - torch.Size([512, 512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

decoder.layer_stack.2.enc_attn.linear_k.weight - torch.Size([512, 512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

decoder.layer_stack.2.enc_attn.linear_v.weight - torch.Size([512, 512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

decoder.layer_stack.2.enc_attn.fc.weight - torch.Size([512, 512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

decoder.layer_stack.2.mlp.w_1.weight - torch.Size([2048, 512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

decoder.layer_stack.2.mlp.w_1.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

decoder.layer_stack.2.mlp.w_2.weight - torch.Size([512, 2048]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

decoder.layer_stack.2.mlp.w_2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

decoder.layer_stack.3.norm1.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

decoder.layer_stack.3.norm1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

decoder.layer_stack.3.norm2.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

decoder.layer_stack.3.norm2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

decoder.layer_stack.3.norm3.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

decoder.layer_stack.3.norm3.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

decoder.layer_stack.3.self_attn.linear_q.weight - torch.Size([512, 512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

decoder.layer_stack.3.self_attn.linear_k.weight - torch.Size([512, 512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

decoder.layer_stack.3.self_attn.linear_v.weight - torch.Size([512, 512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

decoder.layer_stack.3.self_attn.fc.weight - torch.Size([512, 512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

decoder.layer_stack.3.enc_attn.linear_q.weight - torch.Size([512, 512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

decoder.layer_stack.3.enc_attn.linear_k.weight - torch.Size([512, 512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

decoder.layer_stack.3.enc_attn.linear_v.weight - torch.Size([512, 512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

decoder.layer_stack.3.enc_attn.fc.weight - torch.Size([512, 512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

decoder.layer_stack.3.mlp.w_1.weight - torch.Size([2048, 512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

decoder.layer_stack.3.mlp.w_1.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

decoder.layer_stack.3.mlp.w_2.weight - torch.Size([512, 2048]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

decoder.layer_stack.3.mlp.w_2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

decoder.layer_stack.4.norm1.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

decoder.layer_stack.4.norm1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

decoder.layer_stack.4.norm2.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

decoder.layer_stack.4.norm2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

decoder.layer_stack.4.norm3.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

decoder.layer_stack.4.norm3.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

decoder.layer_stack.4.self_attn.linear_q.weight - torch.Size([512, 512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

decoder.layer_stack.4.self_attn.linear_k.weight - torch.Size([512, 512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

decoder.layer_stack.4.self_attn.linear_v.weight - torch.Size([512, 512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

decoder.layer_stack.4.self_attn.fc.weight - torch.Size([512, 512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

decoder.layer_stack.4.enc_attn.linear_q.weight - torch.Size([512, 512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

decoder.layer_stack.4.enc_attn.linear_k.weight - torch.Size([512, 512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

decoder.layer_stack.4.enc_attn.linear_v.weight - torch.Size([512, 512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

decoder.layer_stack.4.enc_attn.fc.weight - torch.Size([512, 512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

decoder.layer_stack.4.mlp.w_1.weight - torch.Size([2048, 512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

decoder.layer_stack.4.mlp.w_1.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

decoder.layer_stack.4.mlp.w_2.weight - torch.Size([512, 2048]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

decoder.layer_stack.4.mlp.w_2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

decoder.layer_stack.5.norm1.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

decoder.layer_stack.5.norm1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

decoder.layer_stack.5.norm2.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

decoder.layer_stack.5.norm2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

decoder.layer_stack.5.norm3.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

decoder.layer_stack.5.norm3.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

decoder.layer_stack.5.self_attn.linear_q.weight - torch.Size([512, 512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

decoder.layer_stack.5.self_attn.linear_k.weight - torch.Size([512, 512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

decoder.layer_stack.5.self_attn.linear_v.weight - torch.Size([512, 512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

decoder.layer_stack.5.self_attn.fc.weight - torch.Size([512, 512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

decoder.layer_stack.5.enc_attn.linear_q.weight - torch.Size([512, 512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

decoder.layer_stack.5.enc_attn.linear_k.weight - torch.Size([512, 512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

decoder.layer_stack.5.enc_attn.linear_v.weight - torch.Size([512, 512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

decoder.layer_stack.5.enc_attn.fc.weight - torch.Size([512, 512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

decoder.layer_stack.5.mlp.w_1.weight - torch.Size([2048, 512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

decoder.layer_stack.5.mlp.w_1.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

decoder.layer_stack.5.mlp.w_2.weight - torch.Size([512, 2048]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

decoder.layer_stack.5.mlp.w_2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

decoder.layer_norm.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

decoder.layer_norm.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

decoder.classifier.weight - torch.Size([92, 512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

decoder.classifier.bias - torch.Size([92]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

decoder.cc_head.head.0.weight - torch.Size([2048, 512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

decoder.cc_head.head.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

decoder.cc_head.head.2.weight - torch.Size([512, 2048]): 
The value is the same before and after calling `init_weights` of CornerTransformer  

decoder.cc_head.head.2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CornerTransformer  
